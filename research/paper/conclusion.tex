\section{Conclusion}

BlockBench evaluates whether frontier LLMs genuinely understand smart contract vulnerabilities or merely pattern-match. Our assessment of six models on 263 Solidity samples reveals substantial limitations. Best performance reaches 58\% detection on mixed samples, collapsing to 20\% on Gold Standard audits. Llama 3.1 405B achieves 88\% accuracy yet 18\% TDR, demonstrating binary classification inadequately measures security understanding.

Models exhibit heterogeneous robustness. While GPT-5.2 maintains stable performance across transformations, most models degrade when surface cues are removed. Current frontier LLMs cannot serve as autonomous auditors but show promise in ensemble workflows with mandatory expert review. Future work should develop sanitization-resistant methods and explore hybrid LLM-verification architectures.
