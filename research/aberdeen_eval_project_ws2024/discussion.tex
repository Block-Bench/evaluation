\section{Discussion}

\textbf{Memorization versus Reasoning.}
Sanitization catastrophe reveals reliance on surface lexical cues. Variable name neutralization causes 40-60pp accuracy drops despite identical logic \citep{sanchez2025none}. However, domain shift resilience complicates this interpretation. Replacing blockchain terminology with medical vocabulary maintains 100\% accuracy and 58-73\% TDR, suggesting models learn structural patterns beyond domain tokens \citep{wu2024reasoning}. Models likely operate at multiple representational levels, leveraging lexical hints when available but retaining some structural understanding \citep{chen2021codex}. Insufficient abstraction to compensate for missing cues indicates incomplete robust reasoning development.

The accuracy-TDR gap exposes measurement inadequacies. Llama achieves 43\% accuracy yet 7\% TDR with 83\% lucky guesses, recognizing anomalies without locating specific flaws \citep{jimenez2024swebench}. For practitioners requiring precise vulnerability types and locations, high accuracy with lucky guesses provides minimal value. Traditional metrics reward binary classification but ignore whether models identify the actual vulnerability present.

\textbf{Deployment Implications.}
Current models cannot serve as autonomous auditors. Best performance reaches 45\% TDR, missing over half of vulnerabilities. Low detection combined with high lucky guess rates creates scenarios where models appear confident while misclassifying flaw types \citep{ince2025gendetect}. Ensemble approaches show promise. Grok 4 provides highest coverage, GPT-5.2 offers reliable precision, and Claude delivers superior explanations. Workflows combining complementary strengths with mandatory human review position LLMs as assistants rather than replacements \citep{hu2023gptlens}.

Adversarial prompt vulnerability reveals authority bias susceptibility. Suggestive framing collapses detection in some models while improving others, indicating training-specific rather than inherent limitations.

\textbf{Limitations.}
Our 58-sample evaluation reveals systematic patterns but warrants larger replication. Gold Standard contains only 10 samples. We evaluate zero-shot prompting only. Chain-of-thought or retrieval augmentation may improve performance. Future work should expand to hundreds of samples across blockchains, develop sanitization-resistant methods using control flow analysis, and explore hybrid LLM-verification approaches \citep{liu2024propertygpt}.
