\section{Related Work}

\paragraph{Traditional Smart Contract Analysis.}
Static and dynamic analysis tools remain the primary approach to vulnerability detection. Slither \citep{feist2019slither} performs dataflow analysis, Mythril \citep{mueller2017mythril} uses symbolic execution, and Securify \citep{tsankov2018securify} employs abstract interpretation. These tools achieve reasonable precision on well-defined vulnerability classes but exhibit significant false positive rates and limited coverage of complex semantic flaws \citep{durieux2020empirical}.

\paragraph{LLM-Based Vulnerability Detection.}
Recent work explores LLMs for smart contract analysis. GPTLens \citep{hu2023gptlens} employs adversarial auditor-critic interactions, while PropertyGPT \citep{liu2024propertygpt} combines retrieval-augmented generation with formal verification. Fine-tuned models achieve over 90\% accuracy on benchmarks \citep{hossain2025leveraging}, though performance degrades substantially on real-world contracts \citep{ince2025gendetect}.

\paragraph{Benchmark Datasets.}
SmartBugs Curated \citep{ferreira2020smartbugs} provides 143 annotated contracts as a standard evaluation dataset, while SolidiFI \citep{ghaleb2020solidifi} uses bug injection to create controlled samples. Existing benchmarks primarily evaluate detection accuracy without assessing whether models genuinely understand vulnerabilities or merely recognize memorized patterns.

\paragraph{LLM Robustness and Memorization.}
Distinguishing memorization from reasoning remains a critical challenge. Models exhibit high sensitivity to input modifications, with performance drops of up to 57\% on paraphrased questions \citep{sanchez2025none}. \citet{wu2024reasoning} show that LLMs often fail on counterfactual variations despite solving canonical forms, suggesting pattern memorization. Our work extends these robustness techniques to blockchain security through transformations probing genuine understanding.
