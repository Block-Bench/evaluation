# GS Direct Summary

**Judge:** codestral
**Generated:** 2026-01-06T00:30:48.098401+00:00
**Models Evaluated:** 7

## Model Rankings (by TDR)

| Rank | Model | TDR | Precision | F1 | Verdict Acc | RCIR | AVA | FSV |
|------|-------|-----|-----------|----|-----------|----|-----|-----|
| 1 | Gemini 3 Pro HE | 29.4% | 69.2% | 41.3% | 82.4% | 0.91 | 0.90 | 0.85 |
| 2 | Claude Opus 4.5 | 17.6% | 83.9% | 29.2% | 67.6% | 0.88 | 0.85 | 0.78 |
| 3 | GPT-5.2 | 14.7% | 70.6% | 24.3% | 44.1% | 0.90 | 0.87 | 0.84 |
| 4 | DeepSeek V3.2 | 11.8% | 48.7% | 19.0% | 76.5% | 0.85 | 0.85 | 0.85 |
| 5 | Llama 4 Maverick | 11.8% | 31.1% | 17.1% | 76.5% | 0.85 | 0.80 | 0.72 |
| 6 | Grok 4 Fast | 2.9% | 37.5% | 5.5% | 20.6% | 0.80 | 0.80 | 0.70 |
| 7 | Qwen3 Coder Plus | 0.0% | 41.7% | 0.0% | 50.0% | - | - | - |

## Metrics Legend

- **TDR**: Target Detection Rate - % of target vulnerabilities correctly identified
- **Precision**: True positives / (True positives + False positives)
- **F1**: Harmonic mean of Precision and TDR
- **Verdict Acc**: % of correct vulnerable/safe verdicts
- **RCIR**: Root Cause Identification Rating (0-1)
- **AVA**: Attack Vector Accuracy (0-1)
- **FSV**: Fix Suggestion Validity (0-1)