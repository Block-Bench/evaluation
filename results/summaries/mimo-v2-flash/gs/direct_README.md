# GS Direct Summary

**Judge:** mimo-v2-flash
**Generated:** 2026-01-06T00:30:48.336602+00:00
**Models Evaluated:** 7

## Model Rankings (by TDR)

| Rank | Model | TDR | Precision | F1 | Verdict Acc | RCIR | AVA | FSV |
|------|-------|-----|-----------|----|-----------|----|-----|-----|
| 1 | Gemini 3 Pro HE | 26.5% | 53.8% | 35.5% | 82.4% | 1.00 | 1.00 | 0.98 |
| 2 | Claude Opus 4.5 | 11.8% | 28.3% | 16.6% | 67.6% | 0.90 | 0.95 | 0.85 |
| 3 | GPT-5.2 | 8.8% | 58.8% | 15.3% | 44.1% | 0.97 | 0.95 | 0.93 |
| 4 | DeepSeek V3.2 | 5.9% | 5.6% | 5.7% | 76.5% | 0.30 | 0.75 | 0.50 |
| 5 | Grok 4 Fast | 2.9% | 50.0% | 5.6% | 20.6% | 1.00 | 1.00 | 0.90 |
| 6 | Llama 4 Maverick | 2.9% | 4.8% | 3.6% | 76.5% | 0.30 | 0.40 | 0.20 |
| 7 | Qwen3 Coder Plus | 0.0% | 0.0% | 0.0% | 50.0% | - | - | - |

## Metrics Legend

- **TDR**: Target Detection Rate - % of target vulnerabilities correctly identified
- **Precision**: True positives / (True positives + False positives)
- **F1**: Harmonic mean of Precision and TDR
- **Verdict Acc**: % of correct vulnerable/safe verdicts
- **RCIR**: Root Cause Identification Rating (0-1)
- **AVA**: Attack Vector Accuracy (0-1)
- **FSV**: Fix Suggestion Validity (0-1)