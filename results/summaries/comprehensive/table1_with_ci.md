# Table 1: Detection Results with 95% Confidence Intervals

## DS Results

| Model | T1 | T2 | T3 | T4 | Avg |
|-------|---:|---:|---:|---:|----:|
| Claude Opus 4.5 | 100.0 [100.0-100.0] | 83.8 [73.0-94.6] | 70.0 [53.3-86.7] | 92.3 [76.9-100.0] | 86.5 |
| Gemini 3 Pro | 75.0 [55.0-95.0] | 78.4 [64.9-89.2] | 50.0 [33.3-66.7] | 92.3 [76.9-100.0] | 73.9 |
| GPT-5.2 | 60.0 [40.0-80.0] | 70.3 [56.8-83.8] | 36.7 [20.0-53.3] | 84.6 [61.5-100.0] | 62.9 |
| DeepSeek v3.2 | 65.0 [45.0-85.0] | 64.9 [48.6-78.4] | 46.7 [30.0-63.3] | 61.5 [38.5-84.6] | 59.5 |
| Llama 4 Mav | 65.0 [45.0-85.0] | 45.9 [29.7-62.2] | 40.0 [23.3-56.7] | 69.2 [46.2-92.3] | 55.0 |
| Qwen3 Coder | 60.0 [40.0-80.0] | 56.8 [43.2-73.0] | 43.3 [26.7-60.0] | 53.8 [23.1-76.9] | 53.5 |
| Grok 4 | 40.0 [20.0-60.0] | 37.8 [21.6-54.1] | 33.3 [16.7-50.0] | 30.8 [7.7-53.8] | 35.5 |

## TC Results

| Model | MinS | San | NoC | Cha | Shp | Tro | FalP | Avg |
|-------|-----:|----:|----:|----:|----:|----:|-----:|----:|
| Claude Opus 4.5 | 71.7 | 54.3 | 50.0 | 43.5 | 50.0 | 32.6 | 54.3 | 50.9 |
| Gemini 3 Pro | 65.2 | 28.3 | 32.6 | 37.0 | 34.8 | 34.8 | 37.0 | 38.5 |
| GPT-5.2 | 54.3 | 34.8 | 37.0 | 28.3 | 30.4 | 30.4 | 37.0 | 36.0 |
| DeepSeek v3.2 | 58.7 | 37.0 | 41.3 | 21.7 | 26.1 | 43.5 | 30.4 | 37.0 |
| Llama 4 Mav | 52.2 | 39.1 | 30.4 | 21.7 | 13.0 | 43.5 | 21.7 | 31.7 |
| Qwen3 Coder | 56.5 | 43.5 | 30.4 | 15.2 | 17.4 | 28.3 | 41.3 | 33.2 |
| Grok 4 | 32.6 | 23.9 | 19.6 | 15.2 | 15.2 | 21.7 | 21.7 | 21.4 |