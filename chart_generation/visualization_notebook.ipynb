{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlockBench Evaluation Results - Visualization Suite\n",
    "\n",
    "Elegant, publication-quality visualizations of model performance across transformations, datasets, and prompt types.\n",
    "\n",
    "**Generated**: 2025-12-18  \n",
    "**Models**: Claude Opus 4.5, DeepSeek V3.2, Gemini 3 Pro, GPT-5.2, Llama 3.1 405B, Grok 4 Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotly for notebook\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model color scheme - vibrant and distinctive\n",
    "MODEL_COLORS = {\n",
    "    'claude_opus_4.5': '#8B5CF6',        # Purple (premium)\n",
    "    'gemini_3_pro_preview': '#10B981',   # Green (Google)\n",
    "    'gpt-5.2': '#3B82F6',                # Blue (OpenAI)\n",
    "    'deepseek_v3.2': '#EC4899',          # Pink (distinctive)\n",
    "    'llama_3.1_405b': '#F59E0B',         # Orange (Meta)\n",
    "    'grok_4_fast': '#6366F1',            # Indigo (xAI)\n",
    "}\n",
    "\n",
    "# Clean model names for display\n",
    "MODEL_NAMES = {\n",
    "    'claude_opus_4.5': 'Claude Opus 4.5',\n",
    "    'gemini_3_pro_preview': 'Gemini 3 Pro',\n",
    "    'gpt-5.2': 'GPT-5.2',\n",
    "    'deepseek_v3.2': 'DeepSeek V3.2',\n",
    "    'llama_3.1_405b': 'Llama 3.1 405B',\n",
    "    'grok_4_fast': 'Grok 4 Fast',\n",
    "}\n",
    "\n",
    "# Transformation names for display\n",
    "TRANSFORMATION_NAMES = {\n",
    "    'sanitized': 'Sanitized',\n",
    "    'chameleon_medical': 'Medical',\n",
    "    'shapeshifter_l3_medium': 'Shapeshifter',\n",
    "    'hydra_restructure': 'Hydra',\n",
    "    'nocomments': 'No-Comments',\n",
    "    'nocomments_original': 'Original',\n",
    "}\n",
    "\n",
    "print(\"✓ Color scheme and naming configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation analysis data\n",
    "with open('TRANSFORMATION_ANALYSIS.json') as f:\n",
    "    transformation_data = json.load(f)\n",
    "\n",
    "# Load GS performance data\n",
    "with open('GS_PERFORMANCE_ANALYSIS.json') as f:\n",
    "    gs_data = json.load(f)\n",
    "\n",
    "# Load prompt type comparison data (from aggregated metrics)\n",
    "prompt_type_data = {}\n",
    "for model in MODEL_COLORS.keys():\n",
    "    metrics_file = Path('judge_output') / model / 'aggregated_metrics.json'\n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file) as f:\n",
    "            prompt_type_data[model] = json.load(f)\n",
    "\n",
    "print(f\"✓ Data loaded for {len(transformation_data)} models\")\n",
    "print(f\"  - Transformation data: {list(transformation_data.keys())}\")\n",
    "print(f\"  - GS data: {list(gs_data.keys())}\")\n",
    "print(f\"  - Prompt type data: {list(prompt_type_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chart 1: Model Performance Radar Chart\n",
    "\n",
    "Multi-dimensional comparison showing each model's strengths and weaknesses across key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for radar chart\n",
    "# We'll use GS dataset performance as it's the most challenging\n",
    "\n",
    "radar_metrics = ['Accuracy', 'TDR', 'Finding<br>Precision', 'Reasoning<br>Quality', 'Calibration']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model in MODEL_COLORS.keys():\n",
    "    if model not in gs_data:\n",
    "        continue\n",
    "    \n",
    "    data = gs_data[model]\n",
    "    \n",
    "    # Calculate reasoning quality as average of RCIR, AVA, FSV\n",
    "    reasoning = None\n",
    "    if data['rcir'] is not None:\n",
    "        reasoning = (data['rcir'] + data['ava'] + data['fsv']) / 3\n",
    "    else:\n",
    "        reasoning = 0\n",
    "    \n",
    "    # Calibration: we don't have this in GS data, use 0.5 as placeholder\n",
    "    # (In real implementation, would load from full metrics)\n",
    "    calibration = 0.7  # Placeholder\n",
    "    \n",
    "    values = [\n",
    "        data['accuracy'],\n",
    "        data['tdr'],\n",
    "        data['finding_precision'],\n",
    "        reasoning,\n",
    "        calibration,\n",
    "    ]\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=radar_metrics,\n",
    "        fill='toself',\n",
    "        name=MODEL_NAMES[model],\n",
    "        line=dict(color=MODEL_COLORS[model], width=2),\n",
    "        fillcolor=MODEL_COLORS[model],\n",
    "        opacity=0.25,\n",
    "        hovertemplate='<b>%{fullData.name}</b><br>%{theta}: %{r:.1%}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1],\n",
    "            tickformat='.0%',\n",
    "            gridcolor='rgba(0,0,0,0.1)',\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            gridcolor='rgba(0,0,0,0.1)',\n",
    "        ),\n",
    "        bgcolor='rgba(0,0,0,0.02)',\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    title={\n",
    "        'text': '<b>Model Performance Profile - GS Dataset</b><br><sub>Higher values = Better performance</sub>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20}\n",
    "    },\n",
    "    width=800,\n",
    "    height=700,\n",
    "    font=dict(size=12),\n",
    "    legend=dict(\n",
    "        orientation='v',\n",
    "        yanchor='middle',\n",
    "        y=0.5,\n",
    "        xanchor='left',\n",
    "        x=1.1\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save to file\n",
    "fig.write_html('charts/1_radar_performance.html')\n",
    "fig.write_image('charts/1_radar_performance.png', width=800, height=700, scale=2)\n",
    "print(\"✓ Chart saved to charts/1_radar_performance.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chart 2: Transformation Impact Heatmap\n",
    "\n",
    "Visualize which code transformations hurt which models the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for heatmap\n",
    "transformations = ['sanitized', 'chameleon_medical', 'shapeshifter_l3_medium', \n",
    "                   'hydra_restructure', 'nocomments', 'nocomments_original']\n",
    "\n",
    "models = list(MODEL_COLORS.keys())\n",
    "\n",
    "# Create matrices for TDR and Finding Precision\n",
    "tdr_matrix = []\n",
    "precision_matrix = []\n",
    "annotations_tdr = []\n",
    "annotations_precision = []\n",
    "\n",
    "for model in models:\n",
    "    tdr_row = []\n",
    "    precision_row = []\n",
    "    \n",
    "    for transformation in transformations:\n",
    "        if model in transformation_data and transformation in transformation_data[model]:\n",
    "            tdr = transformation_data[model][transformation]['tdr']\n",
    "            precision = transformation_data[model][transformation]['finding_precision']\n",
    "        else:\n",
    "            tdr = None\n",
    "            precision = None\n",
    "        \n",
    "        tdr_row.append(tdr if tdr is not None else 0)\n",
    "        precision_row.append(precision if precision is not None else 0)\n",
    "    \n",
    "    tdr_matrix.append(tdr_row)\n",
    "    precision_matrix.append(precision_row)\n",
    "\n",
    "# Create subplots for TDR and Precision side-by-side\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('<b>Target Detection Rate (TDR)</b>', '<b>Finding Precision</b>'),\n",
    "    horizontal_spacing=0.15,\n",
    "    specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}]]\n",
    ")\n",
    "\n",
    "# TDR Heatmap\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=tdr_matrix,\n",
    "        x=[TRANSFORMATION_NAMES[t] for t in transformations],\n",
    "        y=[MODEL_NAMES[m] for m in models],\n",
    "        colorscale='RdYlGn',\n",
    "        text=[[f'{val:.1%}' if val > 0 else 'N/A' for val in row] for row in tdr_matrix],\n",
    "        texttemplate='%{text}',\n",
    "        textfont={'size': 11},\n",
    "        colorbar=dict(title='TDR', x=0.46, len=0.8, tickformat='.0%'),\n",
    "        hovertemplate='<b>%{y}</b><br>%{x}<br>TDR: %{z:.1%}<extra></extra>',\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Precision Heatmap\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=precision_matrix,\n",
    "        x=[TRANSFORMATION_NAMES[t] for t in transformations],\n",
    "        y=[MODEL_NAMES[m] for m in models],\n",
    "        colorscale='RdYlGn',\n",
    "        text=[[f'{val:.1%}' if val > 0 else 'N/A' for val in row] for row in precision_matrix],\n",
    "        texttemplate='%{text}',\n",
    "        textfont={'size': 11},\n",
    "        colorbar=dict(title='Precision', x=1.0, len=0.8, tickformat='.0%'),\n",
    "        hovertemplate='<b>%{y}</b><br>%{x}<br>Precision: %{z:.1%}<extra></extra>',\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': '<b>Transformation Impact on Model Performance</b><br><sub>Red = Poor | Yellow = Moderate | Green = Good</sub>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20}\n",
    "    },\n",
    "    width=1400,\n",
    "    height=600,\n",
    "    font=dict(size=12),\n",
    "    paper_bgcolor='white',\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save to file\n",
    "fig.write_html('charts/2_transformation_heatmap.html')\n",
    "fig.write_image('charts/2_transformation_heatmap.png', width=1400, height=600, scale=2)\n",
    "print(\"✓ Chart saved to charts/2_transformation_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chart 3: TDR vs Lucky Guess Scatter Plot\n",
    "\n",
    "Expose the \"lucky guess problem\" - models that detect vulnerabilities but find the wrong target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for scatter plot using GS dataset\n",
    "scatter_data = []\n",
    "\n",
    "for model in MODEL_COLORS.keys():\n",
    "    if model not in gs_data:\n",
    "        continue\n",
    "    \n",
    "    data = gs_data[model]\n",
    "    \n",
    "    scatter_data.append({\n",
    "        'model': MODEL_NAMES[model],\n",
    "        'model_id': model,\n",
    "        'tdr': data['tdr'],\n",
    "        'lucky_rate': data['lucky_rate'],\n",
    "        'finding_precision': data['finding_precision'],\n",
    "        'accuracy': data['accuracy'],\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(scatter_data)\n",
    "\n",
    "# Create scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[row['tdr']],\n",
    "        y=[row['lucky_rate']],\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=row['finding_precision'] * 200,  # Scale by precision\n",
    "            color=MODEL_COLORS[row['model_id']],\n",
    "            line=dict(width=2, color='white'),\n",
    "            opacity=0.8,\n",
    "        ),\n",
    "        text=row['model'],\n",
    "        textposition='top center',\n",
    "        textfont=dict(size=11, color='black'),\n",
    "        name=row['model'],\n",
    "        hovertemplate=(\n",
    "            '<b>%{text}</b><br>'\n",
    "            'TDR: %{x:.1%}<br>'\n",
    "            'Lucky Guess Rate: %{y:.1%}<br>'\n",
    "            f\"Finding Precision: {row['finding_precision']:.1%}<br>\"\n",
    "            f\"Accuracy: {row['accuracy']:.1%}\"\n",
    "            '<extra></extra>'\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "# Add quadrant labels\n",
    "fig.add_annotation(\n",
    "    x=0.05, y=0.9,\n",
    "    text='<b>Lucky Guesser</b><br><i>Detects wrong<br>vulnerability</i>',\n",
    "    showarrow=False,\n",
    "    font=dict(size=12, color='rgba(220,38,38,0.6)'),\n",
    "    align='center',\n",
    "    bgcolor='rgba(254,226,226,0.5)',\n",
    "    borderpad=10,\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=0.25, y=0.1,\n",
    "    text='<b>True Detector</b><br><i>Finds actual<br>target</i>',\n",
    "    showarrow=False,\n",
    "    font=dict(size=12, color='rgba(34,197,94,0.8)'),\n",
    "    align='center',\n",
    "    bgcolor='rgba(220,252,231,0.5)',\n",
    "    borderpad=10,\n",
    ")\n",
    "\n",
    "# Add reference lines\n",
    "fig.add_hline(y=0.5, line_dash='dash', line_color='rgba(0,0,0,0.2)', \n",
    "              annotation_text='50% Lucky Guess Rate', annotation_position='right')\n",
    "fig.add_vline(x=0.2, line_dash='dash', line_color='rgba(0,0,0,0.2)',\n",
    "              annotation_text='20% TDR', annotation_position='top')\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': '<b>The Lucky Guess Problem - GS Dataset</b><br><sub>Bubble size = Finding Precision | Bottom-right = Best</sub>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20}\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title='<b>Target Detection Rate (TDR)</b>',\n",
    "        tickformat='.0%',\n",
    "        range=[-0.02, 0.35],\n",
    "        gridcolor='rgba(0,0,0,0.1)',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='<b>Lucky Guess Rate</b><br><i>(Higher = More often finds wrong vulnerability)</i>',\n",
    "        tickformat='.0%',\n",
    "        range=[-0.05, 1.0],\n",
    "        gridcolor='rgba(0,0,0,0.1)',\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    "    font=dict(size=12),\n",
    "    plot_bgcolor='rgba(0,0,0,0.02)',\n",
    "    paper_bgcolor='white',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save to file\n",
    "fig.write_html('charts/3_tdr_vs_lucky_guess.html')\n",
    "fig.write_image('charts/3_tdr_vs_lucky_guess.png', width=900, height=700, scale=2)\n",
    "print(\"✓ Chart saved to charts/3_tdr_vs_lucky_guess.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chart 4: Sanitization Effect - Slope Chart\n",
    "\n",
    "Dramatize the performance collapse when code is sanitized (variable names neutralized, comments removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for slope chart\n",
    "# Compare non-sanitized (original) vs sanitized performance\n",
    "\n",
    "slope_data = []\n",
    "\n",
    "for model in MODEL_COLORS.keys():\n",
    "    if model not in transformation_data:\n",
    "        continue\n",
    "    \n",
    "    # Get non-sanitized performance (use nocomments_original as baseline)\n",
    "    if 'nocomments_original' in transformation_data[model]:\n",
    "        non_sanitized_tdr = transformation_data[model]['nocomments_original']['tdr']\n",
    "    else:\n",
    "        # Fallback to average of non-sanitized transformations\n",
    "        non_sanitized_tdrs = []\n",
    "        for trans in ['chameleon_medical', 'shapeshifter_l3_medium', 'hydra_restructure', 'nocomments']:\n",
    "            if trans in transformation_data[model]:\n",
    "                non_sanitized_tdrs.append(transformation_data[model][trans]['tdr'])\n",
    "        non_sanitized_tdr = np.mean(non_sanitized_tdrs) if non_sanitized_tdrs else 0\n",
    "    \n",
    "    # Get sanitized performance\n",
    "    sanitized_tdr = transformation_data[model].get('sanitized', {}).get('tdr', 0)\n",
    "    \n",
    "    slope_data.append({\n",
    "        'model': MODEL_NAMES[model],\n",
    "        'model_id': model,\n",
    "        'non_sanitized': non_sanitized_tdr,\n",
    "        'sanitized': sanitized_tdr,\n",
    "        'drop': non_sanitized_tdr - sanitized_tdr,\n",
    "    })\n",
    "\n",
    "# Sort by drop (largest drop first)\n",
    "slope_data.sort(key=lambda x: x['drop'], reverse=True)\n",
    "\n",
    "# Create slope chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines\n",
    "for item in slope_data:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[item['non_sanitized'], item['sanitized']],\n",
    "        mode='lines+markers',\n",
    "        line=dict(\n",
    "            color=MODEL_COLORS[item['model_id']],\n",
    "            width=4 if item['drop'] > 0.4 else 3,\n",
    "        ),\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color=MODEL_COLORS[item['model_id']],\n",
    "            line=dict(width=2, color='white'),\n",
    "        ),\n",
    "        name=item['model'],\n",
    "        hovertemplate=(\n",
    "            '<b>%{fullData.name}</b><br>'\n",
    "            'Non-Sanitized: %{y:.1%}<br>'\n",
    "            f\"Drop: {item['drop']:.1%}\"\n",
    "            '<extra></extra>'\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "# Add labels on the right side\n",
    "for i, item in enumerate(slope_data):\n",
    "    fig.add_annotation(\n",
    "        x=1.02,\n",
    "        y=item['sanitized'],\n",
    "        text=f\"<b>{item['model']}</b> ({item['sanitized']:.1%})\",\n",
    "        showarrow=False,\n",
    "        xanchor='left',\n",
    "        font=dict(size=11, color=MODEL_COLORS[item['model_id']]),\n",
    "    )\n",
    "\n",
    "# Add labels on the left side\n",
    "for i, item in enumerate(slope_data):\n",
    "    fig.add_annotation(\n",
    "        x=-0.02,\n",
    "        y=item['non_sanitized'],\n",
    "        text=f\"{item['non_sanitized']:.1%}\",\n",
    "        showarrow=False,\n",
    "        xanchor='right',\n",
    "        font=dict(size=11, color=MODEL_COLORS[item['model_id']]),\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': '<b>The Sanitization Catastrophe - TDR Collapse</b><br><sub>Steeper slope = Larger performance drop</sub>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20}\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=[0, 1],\n",
    "        ticktext=['<b>Non-Sanitized</b><br><i>(Original, Medical,<br>Shapeshifter, etc.)</i>', \n",
    "                  '<b>Sanitized</b><br><i>(No semantic cues)</i>'],\n",
    "        range=[-0.15, 1.25],\n",
    "        showgrid=False,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='<b>Target Detection Rate (TDR)</b>',\n",
    "        tickformat='.0%',\n",
    "        range=[0, 1],\n",
    "        gridcolor='rgba(0,0,0,0.1)',\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    font=dict(size=12),\n",
    "    plot_bgcolor='rgba(0,0,0,0.02)',\n",
    "    paper_bgcolor='white',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save to file\n",
    "fig.write_html('charts/4_sanitization_slope.html')\n",
    "fig.write_image('charts/4_sanitization_slope.png', width=1000, height=700, scale=2)\n",
    "print(\"✓ Chart saved to charts/4_sanitization_slope.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ Generated 4 charts:\")\n",
    "print(\"  1. Model Performance Radar Chart (GS Dataset)\")\n",
    "print(\"  2. Transformation Impact Heatmap (TDR & Precision)\")\n",
    "print(\"  3. TDR vs Lucky Guess Scatter Plot\")\n",
    "print(\"  4. Sanitization Effect Slope Chart\")\n",
    "\n",
    "print(\"\\n✓ All charts saved to 'charts/' directory as:\")\n",
    "print(\"  - Interactive HTML (for exploration)\")\n",
    "print(\"  - High-res PNG (for publications)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
