{
  "total_samples": 67,
  "vulnerable_samples": 67,
  "safe_samples": 0,
  "detection": {
    "accuracy": 0.6865671641791045,
    "precision": 1.0,
    "recall": 0.6865671641791045,
    "f1": 0.8141592920353982,
    "f2": 0.732484076433121,
    "fpr": 0,
    "fnr": 0.31343283582089554,
    "tp": 46,
    "tn": 0,
    "fp": 0,
    "fn": 21
  },
  "target_finding": {
    "target_detection_rate": 0.44776119402985076,
    "lucky_guess_rate": 0.41304347826086957,
    "bonus_discovery_rate": 0.47761194029850745,
    "target_found_count": 30,
    "lucky_guess_count": 19
  },
  "finding_quality": {
    "finding_precision": 0.503448275862069,
    "invalid_rate": 0.496551724137931,
    "hallucination_rate": 0.013793103448275862,
    "over_flagging_score": 1.0746268656716418,
    "avg_findings_per_sample": 2.1641791044776117,
    "total_findings": 145,
    "valid_findings": 73,
    "invalid_findings": 72,
    "hallucinated_findings": 2
  },
  "reasoning_quality": {
    "mean_rcir": 0.9833333333333333,
    "mean_ava": 1.0,
    "mean_fsv": 0.9666666666666667,
    "std_rcir": 0.06236095644623236,
    "std_ava": 0.0,
    "std_fsv": 0.08498365855987976,
    "n_samples_with_reasoning": 30
  },
  "type_accuracy": {
    "exact_match_rate": 0.8,
    "semantic_match_rate": 0.9666666666666667,
    "partial_match_rate": 0.03333333333333333,
    "n_samples": 30
  },
  "calibration": {
    "ece": 0.2120689655172414,
    "mce": 0.21666666666666667,
    "overconfidence_rate": 0.2142857142857143,
    "underconfidence_rate": 0.0,
    "brier_score": 0.20198275862068965,
    "n_samples": 58
  },
  "composite": {
    "true_understanding_score": 0.22166752444673188,
    "sui": 0.6952049957766625,
    "sui_components": {
      "f2": 0.732484076433121,
      "target_detection": 0.44776119402985076,
      "finding_precision": 0.503448275862069,
      "avg_reasoning": 0.9833333333333334,
      "calibration": 0.7879310344827586
    },
    "lucky_guess_indicator": 0.2388059701492537
  },
  "by_prompt_type": {
    "direct": {
      "total_samples": 58,
      "vulnerable_samples": 58,
      "safe_samples": 0,
      "detection": {
        "accuracy": 0.7931034482758621,
        "precision": 1.0,
        "recall": 0.7931034482758621,
        "f1": 0.8846153846153846,
        "f2": 0.827338129496403,
        "fpr": 0,
        "fnr": 0.20689655172413793,
        "tp": 46,
        "tn": 0,
        "fp": 0,
        "fn": 12
      },
      "target_finding": {
        "target_detection_rate": 0.46551724137931033,
        "lucky_guess_rate": 0.41304347826086957,
        "bonus_discovery_rate": 0.5344827586206896,
        "target_found_count": 27,
        "lucky_guess_count": 19
      },
      "finding_quality": {
        "finding_precision": 0.6831683168316832,
        "invalid_rate": 0.31683168316831684,
        "hallucination_rate": 0.019801980198019802,
        "over_flagging_score": 0.5517241379310345,
        "avg_findings_per_sample": 1.7413793103448276,
        "total_findings": 101,
        "valid_findings": 69,
        "invalid_findings": 32,
        "hallucinated_findings": 2
      },
      "reasoning_quality": {
        "mean_rcir": 0.9814814814814815,
        "mean_ava": 1.0,
        "mean_fsv": 0.9629629629629629,
        "std_rcir": 0.06547285010986552,
        "std_ava": 0.0,
        "std_fsv": 0.08881169487616149,
        "n_samples_with_reasoning": 27
      },
      "type_accuracy": {
        "exact_match_rate": 0.7777777777777778,
        "semantic_match_rate": 0.9629629629629629,
        "partial_match_rate": 0.037037037037037035,
        "n_samples": 27
      },
      "calibration": {
        "ece": 0.2120689655172414,
        "mce": 0.21666666666666667,
        "overconfidence_rate": 0.2142857142857143,
        "underconfidence_rate": 0.0,
        "brier_score": 0.20198275862068965,
        "n_samples": 58
      },
      "composite": {
        "true_understanding_score": 0.3121372482075793,
        "sui": 0.749852564062327,
        "sui_components": {
          "f2": 0.827338129496403,
          "target_detection": 0.46551724137931033,
          "finding_precision": 0.6831683168316832,
          "avg_reasoning": 0.9814814814814814,
          "calibration": 0.7879310344827586
        },
        "lucky_guess_indicator": 0.32758620689655177
      }
    },
    "naturalistic": {
      "total_samples": 4,
      "vulnerable_samples": 4,
      "safe_samples": 0,
      "detection": {
        "accuracy": 0.0,
        "precision": 0,
        "recall": 0.0,
        "f1": 0,
        "f2": 0,
        "fpr": 0,
        "fnr": 1.0,
        "tp": 0,
        "tn": 0,
        "fp": 0,
        "fn": 4
      },
      "target_finding": {
        "target_detection_rate": 0.5,
        "lucky_guess_rate": 0,
        "bonus_discovery_rate": 0.25,
        "target_found_count": 2,
        "lucky_guess_count": 0
      },
      "finding_quality": {
        "finding_precision": 0.13043478260869565,
        "invalid_rate": 0.8695652173913043,
        "hallucination_rate": 0.0,
        "over_flagging_score": 5.0,
        "avg_findings_per_sample": 5.75,
        "total_findings": 23,
        "valid_findings": 3,
        "invalid_findings": 20,
        "hallucinated_findings": 0
      },
      "reasoning_quality": {
        "mean_rcir": 1.0,
        "mean_ava": 1.0,
        "mean_fsv": 1.0,
        "std_rcir": 0.0,
        "std_ava": 0.0,
        "std_fsv": 0.0,
        "n_samples_with_reasoning": 2
      },
      "type_accuracy": {
        "exact_match_rate": 1.0,
        "semantic_match_rate": 1.0,
        "partial_match_rate": 0.0,
        "n_samples": 2
      },
      "calibration": {
        "ece": null,
        "mce": null,
        "overconfidence_rate": null,
        "underconfidence_rate": null,
        "brier_score": null,
        "n_samples": 0
      },
      "composite": {
        "true_understanding_score": 0.06521739130434784,
        "sui": 0.44456521739130433,
        "sui_components": {
          "f2": 0,
          "target_detection": 0.5,
          "finding_precision": 0.13043478260869565,
          "avg_reasoning": 1.0,
          "calibration": 0.5
        },
        "lucky_guess_indicator": -0.5
      }
    },
    "adversarial": {
      "total_samples": 5,
      "vulnerable_samples": 5,
      "safe_samples": 0,
      "detection": {
        "accuracy": 0.0,
        "precision": 0,
        "recall": 0.0,
        "f1": 0,
        "f2": 0,
        "fpr": 0,
        "fnr": 1.0,
        "tp": 0,
        "tn": 0,
        "fp": 0,
        "fn": 5
      },
      "target_finding": {
        "target_detection_rate": 0.2,
        "lucky_guess_rate": 0,
        "bonus_discovery_rate": 0.0,
        "target_found_count": 1,
        "lucky_guess_count": 0
      },
      "finding_quality": {
        "finding_precision": 0.047619047619047616,
        "invalid_rate": 0.9523809523809523,
        "hallucination_rate": 0.0,
        "over_flagging_score": 4.0,
        "avg_findings_per_sample": 4.2,
        "total_findings": 21,
        "valid_findings": 1,
        "invalid_findings": 20,
        "hallucinated_findings": 0
      },
      "reasoning_quality": {
        "mean_rcir": 1.0,
        "mean_ava": 1.0,
        "mean_fsv": 1.0,
        "std_rcir": 0.0,
        "std_ava": 0.0,
        "std_fsv": 0.0,
        "n_samples_with_reasoning": 1
      },
      "type_accuracy": {
        "exact_match_rate": 1.0,
        "semantic_match_rate": 1.0,
        "partial_match_rate": 0.0,
        "n_samples": 1
      },
      "calibration": {
        "ece": null,
        "mce": null,
        "overconfidence_rate": null,
        "underconfidence_rate": null,
        "brier_score": null,
        "n_samples": 0
      },
      "composite": {
        "true_understanding_score": 0.009523809523809535,
        "sui": 0.35714285714285715,
        "sui_components": {
          "f2": 0,
          "target_detection": 0.2,
          "finding_precision": 0.047619047619047616,
          "avg_reasoning": 1.0,
          "calibration": 0.5
        },
        "lucky_guess_indicator": -0.2
      }
    }
  }
}