{
  "snapshot_timestamp": "2025-12-18T19:05:05.359828",
  "sample_count": 44,
  "metrics": {
    "total_samples": 44,
    "vulnerable_samples": 44,
    "safe_samples": 0,
    "detection": {
      "accuracy": 0.8636363636363636,
      "precision": 1.0,
      "recall": 0.8636363636363636,
      "f1": 0.9268292682926829,
      "f2": 0.8878504672897197,
      "fpr": 0,
      "fnr": 0.13636363636363635,
      "tp": 38,
      "tn": 0,
      "fp": 0,
      "fn": 6
    },
    "target_finding": {
      "target_detection_rate": 0.5227272727272727,
      "lucky_guess_rate": 0.39473684210526316,
      "bonus_discovery_rate": 0.6590909090909091,
      "target_found_count": 23,
      "lucky_guess_count": 15
    },
    "finding_quality": {
      "finding_precision": 0.5723684210526315,
      "invalid_rate": 0.4276315789473684,
      "hallucination_rate": 0.0,
      "over_flagging_score": 1.4772727272727273,
      "avg_findings_per_sample": 3.4545454545454546,
      "total_findings": 152,
      "valid_findings": 87,
      "invalid_findings": 65,
      "hallucinated_findings": 0
    },
    "reasoning_quality": {
      "mean_rcir": 0.967391304347826,
      "mean_ava": 0.9891304347826086,
      "mean_fsv": 0.9456521739130435,
      "std_rcir": 0.08419529013494384,
      "std_ava": 0.050982779998080756,
      "std_fsv": 0.12675982380098477,
      "n_samples_with_reasoning": 23
    },
    "type_accuracy": {
      "exact_match_rate": 0.6521739130434783,
      "semantic_match_rate": 1.0,
      "partial_match_rate": 0.0,
      "n_samples": 23
    },
    "calibration": {
      "ece": 0.08351351351351333,
      "mce": 0.22375,
      "overconfidence_rate": 0.08108108108108103,
      "underconfidence_rate": 0.0,
      "brier_score": 0.06044594594594597,
      "n_samples": 37
    },
    "composite": {
      "true_understanding_score": 0.2894363038277512,
      "sui": 0.771996172897748,
      "sui_components": {
        "f2": 0.8878504672897197,
        "target_detection": 0.5227272727272727,
        "finding_precision": 0.5723684210526315,
        "avg_reasoning": 0.967391304347826,
        "calibration": 0.9164864864864867
      },
      "lucky_guess_indicator": 0.34090909090909094
    },
    "by_prompt_type": {
      "direct": {
        "total_samples": 37,
        "vulnerable_samples": 37,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.918918918918919,
          "precision": 1.0,
          "recall": 0.918918918918919,
          "f1": 0.9577464788732395,
          "f2": 0.934065934065934,
          "fpr": 0,
          "fnr": 0.08108108108108109,
          "tp": 34,
          "tn": 0,
          "fp": 0,
          "fn": 3
        },
        "target_finding": {
          "target_detection_rate": 0.5675675675675675,
          "lucky_guess_rate": 0.38235294117647056,
          "bonus_discovery_rate": 0.7297297297297297,
          "target_found_count": 21,
          "lucky_guess_count": 13
        },
        "finding_quality": {
          "finding_precision": 0.7281553398058253,
          "invalid_rate": 0.27184466019417475,
          "hallucination_rate": 0.0,
          "over_flagging_score": 0.7567567567567568,
          "avg_findings_per_sample": 2.7837837837837838,
          "total_findings": 103,
          "valid_findings": 75,
          "invalid_findings": 28,
          "hallucinated_findings": 0
        },
        "reasoning_quality": {
          "mean_rcir": 0.9642857142857143,
          "mean_ava": 0.9880952380952381,
          "mean_fsv": 0.9404761904761905,
          "std_rcir": 0.08748177652797064,
          "std_ava": 0.053239713749994984,
          "std_fsv": 0.13149239306175312,
          "n_samples_with_reasoning": 21
        },
        "type_accuracy": {
          "exact_match_rate": 0.6190476190476191,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 21
        },
        "calibration": {
          "ece": 0.08351351351351333,
          "mce": 0.22375,
          "overconfidence_rate": 0.08108108108108103,
          "underconfidence_rate": 0.0,
          "brier_score": 0.06044594594594597,
          "n_samples": 37
        },
        "composite": {
          "true_understanding_score": 0.39851744948832335,
          "sui": 0.8173517535993264,
          "sui_components": {
            "f2": 0.934065934065934,
            "target_detection": 0.5675675675675675,
            "finding_precision": 0.7281553398058253,
            "avg_reasoning": 0.9642857142857144,
            "calibration": 0.9164864864864867
          },
          "lucky_guess_indicator": 0.3513513513513514
        }
      },
      "adversarial": {
        "total_samples": 4,
        "vulnerable_samples": 4,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.5,
          "precision": 1.0,
          "recall": 0.5,
          "f1": 0.6666666666666666,
          "f2": 0.5555555555555556,
          "fpr": 0,
          "fnr": 0.5,
          "tp": 2,
          "tn": 0,
          "fp": 0,
          "fn": 2
        },
        "target_finding": {
          "target_detection_rate": 0.25,
          "lucky_guess_rate": 0.5,
          "bonus_discovery_rate": 0.25,
          "target_found_count": 1,
          "lucky_guess_count": 1
        },
        "finding_quality": {
          "finding_precision": 0.2916666666666667,
          "invalid_rate": 0.7083333333333334,
          "hallucination_rate": 0.0,
          "over_flagging_score": 4.25,
          "avg_findings_per_sample": 6.0,
          "total_findings": 24,
          "valid_findings": 7,
          "invalid_findings": 17,
          "hallucinated_findings": 0
        },
        "reasoning_quality": {
          "mean_rcir": 1.0,
          "mean_ava": 1.0,
          "mean_fsv": 1.0,
          "std_rcir": 0.0,
          "std_ava": 0.0,
          "std_fsv": 0.0,
          "n_samples_with_reasoning": 1
        },
        "type_accuracy": {
          "exact_match_rate": 1.0,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 1
        },
        "calibration": {
          "ece": null,
          "mce": null,
          "overconfidence_rate": null,
          "underconfidence_rate": null,
          "brier_score": null,
          "n_samples": 0
        },
        "composite": {
          "true_understanding_score": 0.07291666666666666,
          "sui": 0.545138888888889,
          "sui_components": {
            "f2": 0.5555555555555556,
            "target_detection": 0.25,
            "finding_precision": 0.2916666666666667,
            "avg_reasoning": 1.0,
            "calibration": 0.5
          },
          "lucky_guess_indicator": 0.25
        }
      },
      "naturalistic": {
        "total_samples": 3,
        "vulnerable_samples": 3,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.6666666666666666,
          "precision": 1.0,
          "recall": 0.6666666666666666,
          "f1": 0.8,
          "f2": 0.7142857142857142,
          "fpr": 0,
          "fnr": 0.3333333333333333,
          "tp": 2,
          "tn": 0,
          "fp": 0,
          "fn": 1
        },
        "target_finding": {
          "target_detection_rate": 0.3333333333333333,
          "lucky_guess_rate": 0.5,
          "bonus_discovery_rate": 0.3333333333333333,
          "target_found_count": 1,
          "lucky_guess_count": 1
        },
        "finding_quality": {
          "finding_precision": 0.2,
          "invalid_rate": 0.8,
          "hallucination_rate": 0.0,
          "over_flagging_score": 6.666666666666667,
          "avg_findings_per_sample": 8.333333333333334,
          "total_findings": 25,
          "valid_findings": 5,
          "invalid_findings": 20,
          "hallucinated_findings": 0
        },
        "reasoning_quality": {
          "mean_rcir": 1.0,
          "mean_ava": 1.0,
          "mean_fsv": 1.0,
          "std_rcir": 0.0,
          "std_ava": 0.0,
          "std_fsv": 0.0,
          "n_samples_with_reasoning": 1
        },
        "type_accuracy": {
          "exact_match_rate": 1.0,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 1
        },
        "calibration": {
          "ece": null,
          "mce": null,
          "overconfidence_rate": null,
          "underconfidence_rate": null,
          "brier_score": null,
          "n_samples": 0
        },
        "composite": {
          "true_understanding_score": 0.06666666666666665,
          "sui": 0.5919047619047619,
          "sui_components": {
            "f2": 0.7142857142857142,
            "target_detection": 0.3333333333333333,
            "finding_precision": 0.2,
            "avg_reasoning": 1.0,
            "calibration": 0.5
          },
          "lucky_guess_indicator": 0.3333333333333333
        }
      }
    }
  }
}