{
  "subset": "Full Evaluation",
  "results": {
    "balanced": {
      "claude_opus_4.5": {
        "sui": 0.7218308823529411,
        "tdr": 0.5294117647058824,
        "reasoning": 0.9791666666666666,
        "precision": 0.6588235294117647,
        "num_samples": 68
      },
      "gpt-5.2": {
        "sui": 0.7662593002113127,
        "tdr": 0.5588235294117647,
        "reasoning": 0.9736842105263158,
        "precision": 0.7662698412698413,
        "num_samples": 68
      },
      "gemini_3_pro_preview": {
        "sui": 0.7506771664008507,
        "tdr": 0.5757575757575758,
        "reasoning": 0.9627192982456141,
        "precision": 0.7146464646464646,
        "num_samples": 66
      },
      "grok_4": {
        "sui": 0.7028025210084035,
        "tdr": 0.4411764705882353,
        "reasoning": 0.9833333333333335,
        "precision": 0.684453781512605,
        "num_samples": 68
      },
      "deepseek_v3.2": {
        "sui": 0.6223239064856712,
        "tdr": 0.38235294117647056,
        "reasoning": 0.8961538461538462,
        "precision": 0.5894607843137254,
        "num_samples": 68
      },
      "llama_3.1_405b": {
        "sui": 0.4147952203269367,
        "tdr": 0.1791044776119403,
        "reasoning": 0.8680555555555555,
        "precision": 0.20362473347547974,
        "num_samples": 67
      }
    },
    "default": {
      "claude_opus_4.5": {
        "sui": 0.7031617647058823,
        "tdr": 0.5294117647058824,
        "reasoning": 0.9791666666666666,
        "precision": 0.6588235294117647,
        "num_samples": 68
      },
      "gpt-5.2": {
        "sui": 0.745515627303553,
        "tdr": 0.5588235294117647,
        "reasoning": 0.9736842105263158,
        "precision": 0.7662698412698413,
        "num_samples": 68
      },
      "gemini_3_pro_preview": {
        "sui": 0.7335127591706538,
        "tdr": 0.5757575757575758,
        "reasoning": 0.9627192982456141,
        "precision": 0.7146464646464646,
        "num_samples": 66
      },
      "grok_4": {
        "sui": 0.6768067226890757,
        "tdr": 0.4411764705882353,
        "reasoning": 0.9833333333333335,
        "precision": 0.684453781512605,
        "num_samples": 68
      },
      "deepseek_v3.2": {
        "sui": 0.5986255656108597,
        "tdr": 0.38235294117647056,
        "reasoning": 0.8961538461538462,
        "precision": 0.5894607843137254,
        "num_samples": 68
      },
      "llama_3.1_405b": {
        "sui": 0.3931458777540867,
        "tdr": 0.1791044776119403,
        "reasoning": 0.8680555555555555,
        "precision": 0.20362473347547974,
        "num_samples": 67
      }
    },
    "quality_first": {
      "claude_opus_4.5": {
        "sui": 0.7481372549019608,
        "tdr": 0.5294117647058824,
        "reasoning": 0.9791666666666666,
        "precision": 0.6588235294117647,
        "num_samples": 68
      },
      "gpt-5.2": {
        "sui": 0.7870016954150082,
        "tdr": 0.5588235294117647,
        "reasoning": 0.9736842105263158,
        "precision": 0.7662698412698413,
        "num_samples": 68
      },
      "gemini_3_pro_preview": {
        "sui": 0.7722089314194578,
        "tdr": 0.5757575757575758,
        "reasoning": 0.9627192982456141,
        "precision": 0.7146464646464646,
        "num_samples": 66
      },
      "grok_4": {
        "sui": 0.7310224089635855,
        "tdr": 0.4411764705882353,
        "reasoning": 0.9833333333333335,
        "precision": 0.684453781512605,
        "num_samples": 68
      },
      "deepseek_v3.2": {
        "sui": 0.6500056561085973,
        "tdr": 0.38235294117647056,
        "reasoning": 0.8961538461538462,
        "precision": 0.5894607843137254,
        "num_samples": 68
      },
      "llama_3.1_405b": {
        "sui": 0.4620409855484482,
        "tdr": 0.1791044776119403,
        "reasoning": 0.8680555555555555,
        "precision": 0.20362473347547974,
        "num_samples": 67
      }
    },
    "precision_first": {
      "claude_opus_4.5": {
        "sui": 0.7161029411764706,
        "tdr": 0.5294117647058824,
        "reasoning": 0.9791666666666666,
        "precision": 0.6588235294117647,
        "num_samples": 68
      },
      "gpt-5.2": {
        "sui": 0.7662602584893607,
        "tdr": 0.5588235294117647,
        "reasoning": 0.9736842105263158,
        "precision": 0.7662698412698413,
        "num_samples": 68
      },
      "gemini_3_pro_preview": {
        "sui": 0.7474016480595428,
        "tdr": 0.5757575757575758,
        "reasoning": 0.9627192982456141,
        "precision": 0.7146464646464646,
        "num_samples": 66
      },
      "grok_4": {
        "sui": 0.7011344537815126,
        "tdr": 0.4411764705882353,
        "reasoning": 0.9833333333333335,
        "precision": 0.684453781512605,
        "num_samples": 68
      },
      "deepseek_v3.2": {
        "sui": 0.6193363499245852,
        "tdr": 0.38235294117647056,
        "reasoning": 0.8961538461538462,
        "precision": 0.5894607843137254,
        "num_samples": 68
      },
      "llama_3.1_405b": {
        "sui": 0.39559790334044065,
        "tdr": 0.1791044776119403,
        "reasoning": 0.8680555555555555,
        "precision": 0.20362473347547974,
        "num_samples": 67
      }
    },
    "detection_heavy": {
      "claude_opus_4.5": {
        "sui": 0.674203431372549,
        "tdr": 0.5294117647058824,
        "reasoning": 0.9791666666666666,
        "precision": 0.6588235294117647,
        "num_samples": 68
      },
      "gpt-5.2": {
        "sui": 0.7144002776549216,
        "tdr": 0.5588235294117647,
        "reasoning": 0.9736842105263158,
        "precision": 0.7662698412698413,
        "num_samples": 68
      },
      "gemini_3_pro_preview": {
        "sui": 0.7072202286018076,
        "tdr": 0.5757575757575758,
        "reasoning": 0.9627192982456141,
        "precision": 0.7146464646464646,
        "num_samples": 66
      },
      "grok_4": {
        "sui": 0.6375350140056022,
        "tdr": 0.4411764705882353,
        "reasoning": 0.9833333333333335,
        "precision": 0.684453781512605,
        "num_samples": 68
      },
      "deepseek_v3.2": {
        "sui": 0.5625801282051281,
        "tdr": 0.38235294117647056,
        "reasoning": 0.8961538461538462,
        "precision": 0.5894607843137254,
        "num_samples": 68
      },
      "llama_3.1_405b": {
        "sui": 0.35747231106372895,
        "tdr": 0.1791044776119403,
        "reasoning": 0.8680555555555555,
        "precision": 0.20362473347547974,
        "num_samples": 67
      }
    }
  },
  "rankings": {
    "balanced": [
      [
        "gpt-5.2",
        1
      ],
      [
        "gemini_3_pro_preview",
        2
      ],
      [
        "claude_opus_4.5",
        3
      ],
      [
        "grok_4",
        4
      ],
      [
        "deepseek_v3.2",
        5
      ],
      [
        "llama_3.1_405b",
        6
      ]
    ],
    "default": [
      [
        "gpt-5.2",
        1
      ],
      [
        "gemini_3_pro_preview",
        2
      ],
      [
        "claude_opus_4.5",
        3
      ],
      [
        "grok_4",
        4
      ],
      [
        "deepseek_v3.2",
        5
      ],
      [
        "llama_3.1_405b",
        6
      ]
    ],
    "quality_first": [
      [
        "gpt-5.2",
        1
      ],
      [
        "gemini_3_pro_preview",
        2
      ],
      [
        "claude_opus_4.5",
        3
      ],
      [
        "grok_4",
        4
      ],
      [
        "deepseek_v3.2",
        5
      ],
      [
        "llama_3.1_405b",
        6
      ]
    ],
    "precision_first": [
      [
        "gpt-5.2",
        1
      ],
      [
        "gemini_3_pro_preview",
        2
      ],
      [
        "claude_opus_4.5",
        3
      ],
      [
        "grok_4",
        4
      ],
      [
        "deepseek_v3.2",
        5
      ],
      [
        "llama_3.1_405b",
        6
      ]
    ],
    "detection_heavy": [
      [
        "gpt-5.2",
        1
      ],
      [
        "gemini_3_pro_preview",
        2
      ],
      [
        "claude_opus_4.5",
        3
      ],
      [
        "grok_4",
        4
      ],
      [
        "deepseek_v3.2",
        5
      ],
      [
        "llama_3.1_405b",
        6
      ]
    ]
  },
  "correlations": {
    "balanced_vs_default": 1.0,
    "balanced_vs_quality_first": 1.0,
    "balanced_vs_precision_first": 1.0,
    "balanced_vs_detection_heavy": 1.0,
    "default_vs_quality_first": 1.0,
    "default_vs_precision_first": 1.0,
    "default_vs_detection_heavy": 1.0,
    "quality_first_vs_precision_first": 1.0,
    "quality_first_vs_detection_heavy": 1.0,
    "precision_first_vs_detection_heavy": 1.0
  },
  "summary_stats": {
    "avg_correlation": 1.0,
    "std_correlation": 0.0,
    "min_correlation": 1.0,
    "max_correlation": 1.0
  }
}