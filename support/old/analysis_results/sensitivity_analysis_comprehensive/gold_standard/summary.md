# Sensitivity Analysis: Gold Standard

## Rankings by Configuration


### Default

1. Grok 4: SUI=0.481 (TDR=20.0%, R=1.000, P=33.5%)
2. GPT-5.2: SUI=0.477 (TDR=25.0%, R=0.850, P=40.5%)
3. Gemini 3 Pro: SUI=0.442 (TDR=26.3%, R=0.817, P=30.7%)
4. Claude Opus 4.5: SUI=0.439 (TDR=20.0%, R=0.917, P=28.0%)
5. Llama 3.1 405B: SUI=0.323 (TDR=5.3%, R=1.000, P=0.8%)
6. DeepSeek v3.2: SUI=0.309 (TDR=10.0%, R=0.625, P=27.1%)

### Balanced

1. Grok 4: SUI=0.510 (TDR=20.0%, R=1.000, P=33.5%)
2. GPT-5.2: SUI=0.501 (TDR=25.0%, R=0.850, P=40.5%)
3. Claude Opus 4.5: SUI=0.464 (TDR=20.0%, R=0.917, P=28.0%)
4. Gemini 3 Pro: SUI=0.461 (TDR=26.3%, R=0.817, P=30.7%)
5. Llama 3.1 405B: SUI=0.350 (TDR=5.3%, R=1.000, P=0.8%)
6. DeepSeek v3.2: SUI=0.331 (TDR=10.0%, R=0.625, P=27.1%)

### Quality First

1. Grok 4: SUI=0.561 (TDR=20.0%, R=1.000, P=33.5%)
2. GPT-5.2: SUI=0.537 (TDR=25.0%, R=0.850, P=40.5%)
3. Claude Opus 4.5: SUI=0.511 (TDR=20.0%, R=0.917, P=28.0%)
4. Gemini 3 Pro: SUI=0.498 (TDR=26.3%, R=0.817, P=30.7%)
5. Llama 3.1 405B: SUI=0.418 (TDR=5.3%, R=1.000, P=0.8%)
6. DeepSeek v3.2: SUI=0.361 (TDR=10.0%, R=0.625, P=27.1%)

### Precision First

1. Grok 4: SUI=0.494 (TDR=20.0%, R=1.000, P=33.5%)
2. GPT-5.2: SUI=0.492 (TDR=25.0%, R=0.850, P=40.5%)
3. Claude Opus 4.5: SUI=0.447 (TDR=20.0%, R=0.917, P=28.0%)
4. Gemini 3 Pro: SUI=0.447 (TDR=26.3%, R=0.817, P=30.7%)
5. DeepSeek v3.2: SUI=0.326 (TDR=10.0%, R=0.625, P=27.1%)
6. Llama 3.1 405B: SUI=0.319 (TDR=5.3%, R=1.000, P=0.8%)

### Detection Heavy

1. GPT-5.2: SUI=0.439 (TDR=25.0%, R=0.850, P=40.5%)
2. Grok 4: SUI=0.434 (TDR=20.0%, R=1.000, P=33.5%)
3. Gemini 3 Pro: SUI=0.413 (TDR=26.3%, R=0.817, P=30.7%)
4. Claude Opus 4.5: SUI=0.399 (TDR=20.0%, R=0.917, P=28.0%)
5. Llama 3.1 405B: SUI=0.278 (TDR=5.3%, R=1.000, P=0.8%)
6. DeepSeek v3.2: SUI=0.274 (TDR=10.0%, R=0.625, P=27.1%)

## Ranking Stability

- Average Spearman ρ: 0.920 ± 0.046
- Range: [0.829, 1.000]

## Interpretation

Moderate correlation indicates some ranking variation across weight choices.
