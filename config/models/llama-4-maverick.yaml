# Llama 4 Maverick via Vertex AI MaaS
name: "Llama 4 Maverick"
provider: "vertex_llama"
model_id: "meta/llama-4-maverick-17b-128e-instruct-maas"
region: "us-east5"

# Generation parameters
max_tokens: 8192
temperature: 0.0  # Deterministic
timeout: 180

# Retry configuration
max_retries: 3
retry_delay: 2.0

# Cost tracking (per 1M tokens) - MaaS pricing
cost_per_input_token: 0.00000027   # ~$0.27 per 1M input
cost_per_output_token: 0.00000035  # ~$0.35 per 1M output

# Provider-specific settings
supports_json_mode: false
extra_params:
  endpoint: "us-east5-aiplatform.googleapis.com"
