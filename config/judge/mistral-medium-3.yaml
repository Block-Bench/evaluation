# Mistral Medium 3 Judge Configuration
# Default judge model via Vertex AI

name: "Mistral Medium 3"
provider: "vertex_mistral"
model_id: "mistral-medium-3"
region: "us-central1"

# Generation parameters
max_tokens: 4096
temperature: 0.0
timeout: 180

# Retry configuration
max_retries: 3
retry_delay: 2.0

# Pricing: $0.40/1M input, $2.00/1M output
cost_per_input_token: 0.0000004
cost_per_output_token: 0.000002

# Capabilities
supports_json_mode: true
