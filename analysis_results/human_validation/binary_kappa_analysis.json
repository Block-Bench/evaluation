{
  "n_samples": 46,
  "detection_agreement": {
    "agreement_pct": 86.95652173913044,
    "cohen_kappa": 0.0,
    "precision": 0.8695652173913043,
    "recall": 1.0,
    "f1_score": 0.9302325581395349,
    "confusion_matrix": {
      "true_negatives": 0,
      "false_positives": 6,
      "false_negatives": 0,
      "true_positives": 40
    }
  },
  "type_classification_when_both_found": {
    "n_cases": 40,
    "agreement_pct": 92.5,
    "disagreements": [
      {
        "sample_id": "nc_ds_234",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "nc_ds_234",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "ch_medical_nc_ds_159",
        "expert_type": "exact",
        "judge_type": "semantic"
      }
    ]
  },
  "summary": "\nDETECTION AGREEMENT:\n  Overall agreement: 87.0% (40/46 samples)\n  Cohen's \u03ba: 0.00\n  Judge precision: 0.87, recall: 1.00, F1: 0.93\n\nTYPE CLASSIFICATION (when both detected):\n  Agreement: 92.5% (37/40 samples)\n  Disagreements: 3 cases (mostly exact vs. semantic)\n\nINTERPRETATION:\n  \u03ba=0.00 indicates fair agreement on vulnerability detection.\n  When both detect a vulnerability, they agree on classification 92% of the time.\n"
}