{
  "n_samples": 116,
  "detection_agreement": {
    "agreement_pct": 92.24137931034483,
    "cohen_kappa": 0.8431490384615384,
    "precision": 0.8363636363636363,
    "recall": 1.0,
    "f1_score": 0.9108910891089108,
    "confusion_matrix": {
      "true_negatives": 61,
      "false_positives": 9,
      "false_negatives": 0,
      "true_positives": 46
    }
  },
  "type_classification_when_both_found": {
    "n_cases": 46,
    "agreement_pct": 84.78260869565217,
    "disagreements": [
      {
        "sample_id": "sn_tc_003",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "sn_tc_002",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "nc_ds_234",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "sn_tc_004",
        "expert_type": "exact",
        "judge_type": "partial"
      },
      {
        "sample_id": "sn_tc_003",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "nc_ds_234",
        "expert_type": "exact",
        "judge_type": "semantic"
      },
      {
        "sample_id": "ch_medical_nc_ds_159",
        "expert_type": "exact",
        "judge_type": "semantic"
      }
    ]
  },
  "summary": "\nDETECTION AGREEMENT:\n  Overall agreement: 92.2% (107/116 samples)\n  Cohen's \u03ba: 0.84\n  Judge precision: 0.84, recall: 1.00, F1: 0.91\n\nTYPE CLASSIFICATION (when both detected):\n  Agreement: 84.8% (39/46 samples)\n  Disagreements: 7 cases (mostly exact vs. semantic)\n\nINTERPRETATION:\n  \u03ba=0.84 indicates substantial agreement on vulnerability detection.\n  When both detect a vulnerability, they agree on classification 85% of the time.\n"
}