\begin{table*}[t]
\centering
\caption{Model SUI scores and rankings for Full Evaluation subset.}
\label{tab:sui_sensitivity_full_evaluation}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Balanced} & \textbf{Default} & \textbf{Quality-First} & \textbf{Precision-First} & \textbf{Detection-Heavy} \\
\midrule
GPT-5.2 & 0.766 (1) & 0.746 (1) & 0.787 (1) & 0.766 (1) & 0.714 (1) \\\
Gemini 3 Pro & 0.751 (2) & 0.734 (2) & 0.772 (2) & 0.747 (2) & 0.707 (2) \\\
Claude Opus 4.5 & 0.722 (3) & 0.703 (3) & 0.748 (3) & 0.716 (3) & 0.674 (3) \\\
Grok 4 & 0.703 (4) & 0.677 (4) & 0.731 (4) & 0.701 (4) & 0.638 (4) \\\
DeepSeek v3.2 & 0.622 (5) & 0.599 (5) & 0.650 (5) & 0.619 (5) & 0.563 (5) \\\
Llama 3.1 405B & 0.415 (6) & 0.393 (6) & 0.462 (6) & 0.396 (6) & 0.357 (6) \\\
\bottomrule
\end{tabular}
\end{table*}
