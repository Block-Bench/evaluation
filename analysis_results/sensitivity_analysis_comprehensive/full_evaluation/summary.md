# Sensitivity Analysis: Full Evaluation

## Rankings by Configuration


### Default

1. GPT-5.2: SUI=0.746 (TDR=55.9%, R=0.974, P=76.6%)
2. Gemini 3 Pro: SUI=0.734 (TDR=57.6%, R=0.963, P=71.5%)
3. Claude Opus 4.5: SUI=0.703 (TDR=52.9%, R=0.979, P=65.9%)
4. Grok 4: SUI=0.677 (TDR=44.1%, R=0.983, P=68.4%)
5. DeepSeek v3.2: SUI=0.599 (TDR=38.2%, R=0.896, P=58.9%)
6. Llama 3.1 405B: SUI=0.393 (TDR=17.9%, R=0.868, P=20.4%)

### Balanced

1. GPT-5.2: SUI=0.766 (TDR=55.9%, R=0.974, P=76.6%)
2. Gemini 3 Pro: SUI=0.751 (TDR=57.6%, R=0.963, P=71.5%)
3. Claude Opus 4.5: SUI=0.722 (TDR=52.9%, R=0.979, P=65.9%)
4. Grok 4: SUI=0.703 (TDR=44.1%, R=0.983, P=68.4%)
5. DeepSeek v3.2: SUI=0.622 (TDR=38.2%, R=0.896, P=58.9%)
6. Llama 3.1 405B: SUI=0.415 (TDR=17.9%, R=0.868, P=20.4%)

### Quality First

1. GPT-5.2: SUI=0.787 (TDR=55.9%, R=0.974, P=76.6%)
2. Gemini 3 Pro: SUI=0.772 (TDR=57.6%, R=0.963, P=71.5%)
3. Claude Opus 4.5: SUI=0.748 (TDR=52.9%, R=0.979, P=65.9%)
4. Grok 4: SUI=0.731 (TDR=44.1%, R=0.983, P=68.4%)
5. DeepSeek v3.2: SUI=0.650 (TDR=38.2%, R=0.896, P=58.9%)
6. Llama 3.1 405B: SUI=0.462 (TDR=17.9%, R=0.868, P=20.4%)

### Precision First

1. GPT-5.2: SUI=0.766 (TDR=55.9%, R=0.974, P=76.6%)
2. Gemini 3 Pro: SUI=0.747 (TDR=57.6%, R=0.963, P=71.5%)
3. Claude Opus 4.5: SUI=0.716 (TDR=52.9%, R=0.979, P=65.9%)
4. Grok 4: SUI=0.701 (TDR=44.1%, R=0.983, P=68.4%)
5. DeepSeek v3.2: SUI=0.619 (TDR=38.2%, R=0.896, P=58.9%)
6. Llama 3.1 405B: SUI=0.396 (TDR=17.9%, R=0.868, P=20.4%)

### Detection Heavy

1. GPT-5.2: SUI=0.714 (TDR=55.9%, R=0.974, P=76.6%)
2. Gemini 3 Pro: SUI=0.707 (TDR=57.6%, R=0.963, P=71.5%)
3. Claude Opus 4.5: SUI=0.674 (TDR=52.9%, R=0.979, P=65.9%)
4. Grok 4: SUI=0.638 (TDR=44.1%, R=0.983, P=68.4%)
5. DeepSeek v3.2: SUI=0.563 (TDR=38.2%, R=0.896, P=58.9%)
6. Llama 3.1 405B: SUI=0.357 (TDR=17.9%, R=0.868, P=20.4%)

## Ranking Stability

- Average Spearman ρ: 1.000 ± 0.000
- Range: [1.000, 1.000]

## Interpretation

High correlation (ρ > 0.95) indicates robust rankings.
