# Sensitivity Analysis: Difficulty Stratified

## Rankings by Configuration


### Default

1. GPT-5.2: SUI=0.900 (TDR=75.0%, R=1.000, P=100.0%)
2. Gemini 3 Pro: SUI=0.882 (TDR=82.1%, R=1.000, P=84.5%)
3. Claude Opus 4.5: SUI=0.849 (TDR=82.1%, R=1.000, P=73.3%)
4. Grok 4: SUI=0.808 (TDR=60.7%, R=0.990, P=89.3%)
5. DeepSeek v3.2: SUI=0.690 (TDR=53.6%, R=0.937, P=64.9%)
6. Llama 3.1 405B: SUI=0.431 (TDR=21.4%, R=0.972, P=17.9%)

### Balanced

1. GPT-5.2: SUI=0.917 (TDR=75.0%, R=1.000, P=100.0%)
2. Gemini 3 Pro: SUI=0.888 (TDR=82.1%, R=1.000, P=84.5%)
3. Claude Opus 4.5: SUI=0.850 (TDR=82.1%, R=1.000, P=73.3%)
4. Grok 4: SUI=0.831 (TDR=60.7%, R=0.990, P=89.3%)
5. DeepSeek v3.2: SUI=0.706 (TDR=53.6%, R=0.937, P=64.9%)
6. Llama 3.1 405B: SUI=0.452 (TDR=21.4%, R=0.972, P=17.9%)

### Quality First

1. GPT-5.2: SUI=0.925 (TDR=75.0%, R=1.000, P=100.0%)
2. Gemini 3 Pro: SUI=0.900 (TDR=82.1%, R=1.000, P=84.5%)
3. Claude Opus 4.5: SUI=0.866 (TDR=82.1%, R=1.000, P=73.3%)
4. Grok 4: SUI=0.846 (TDR=60.7%, R=0.990, P=89.3%)
5. DeepSeek v3.2: SUI=0.730 (TDR=53.6%, R=0.937, P=64.9%)
6. Llama 3.1 405B: SUI=0.507 (TDR=21.4%, R=0.972, P=17.9%)

### Precision First

1. GPT-5.2: SUI=0.925 (TDR=75.0%, R=1.000, P=100.0%)
2. Gemini 3 Pro: SUI=0.885 (TDR=82.1%, R=1.000, P=84.5%)
3. Claude Opus 4.5: SUI=0.840 (TDR=82.1%, R=1.000, P=73.3%)
4. Grok 4: SUI=0.836 (TDR=60.7%, R=0.990, P=89.3%)
5. DeepSeek v3.2: SUI=0.701 (TDR=53.6%, R=0.937, P=64.9%)
6. Llama 3.1 405B: SUI=0.427 (TDR=21.4%, R=0.972, P=17.9%)

### Detection Heavy

1. GPT-5.2: SUI=0.875 (TDR=75.0%, R=1.000, P=100.0%)
2. Gemini 3 Pro: SUI=0.872 (TDR=82.1%, R=1.000, P=84.5%)
3. Claude Opus 4.5: SUI=0.844 (TDR=82.1%, R=1.000, P=73.3%)
4. Grok 4: SUI=0.774 (TDR=60.7%, R=0.990, P=89.3%)
5. DeepSeek v3.2: SUI=0.664 (TDR=53.6%, R=0.937, P=64.9%)
6. Llama 3.1 405B: SUI=0.395 (TDR=21.4%, R=0.972, P=17.9%)

## Ranking Stability

- Average Spearman ρ: 1.000 ± 0.000
- Range: [1.000, 1.000]

## Interpretation

High correlation (ρ > 0.95) indicates robust rankings.
