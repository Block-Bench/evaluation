{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "human_review_output.schema.json",
  "title": "DS Human Review Output",
  "description": "Schema for expert human evaluation of model predictions.",
  "type": "object",
  "required": [
    "sample_id",
    "model_evaluated",
    "reviewer_id",
    "review_timestamp",
    "verdict_assessment",
    "findings_assessment",
    "overall_quality"
  ],
  "properties": {
    "sample_id": {
      "type": "string",
      "description": "Sample identifier (e.g., ds_t1_001)."
    },
    "tier": {
      "type": "integer",
      "minimum": 1,
      "maximum": 4,
      "description": "Difficulty tier (1-4)."
    },
    "model_evaluated": {
      "type": "string",
      "description": "Model whose output is being reviewed."
    },
    "prompt_type": {
      "type": "string",
      "enum": ["direct", "naturalistic", "adversarial"],
      "description": "Type of prompt used."
    },
    "reviewer_id": {
      "type": "string",
      "description": "Identifier for the human reviewer."
    },
    "review_timestamp": {
      "type": "string",
      "format": "date-time",
      "description": "ISO 8601 timestamp of review."
    },

    "verdict_assessment": {
      "type": "object",
      "description": "Human assessment of model's verdict.",
      "required": ["model_verdict_correct"],
      "properties": {
        "model_verdict_correct": {
          "type": "boolean",
          "description": "Whether model's vulnerable/safe verdict was correct."
        },
        "notes": {
          "type": ["string", "null"],
          "description": "Additional notes on verdict."
        }
      }
    },

    "findings_assessment": {
      "type": "array",
      "description": "Human evaluation of each finding from model.",
      "items": {
        "type": "object",
        "required": ["finding_id", "classification"],
        "properties": {
          "finding_id": {
            "type": "integer",
            "minimum": 0,
            "description": "Index of finding from model output."
          },
          "classification": {
            "type": "string",
            "enum": [
              "TARGET_MATCH",
              "PARTIAL_MATCH",
              "BONUS_VALID",
              "HALLUCINATED",
              "MISCHARACTERIZED",
              "DESIGN_CHOICE",
              "OUT_OF_SCOPE",
              "SECURITY_THEATER",
              "INFORMATIONAL"
            ],
            "description": "Human classification of the finding."
          },
          "type_correct": {
            "type": "boolean",
            "description": "Whether vulnerability type is correct."
          },
          "location_correct": {
            "type": "boolean",
            "description": "Whether location is correct."
          },
          "explanation_quality": {
            "type": "integer",
            "minimum": 1,
            "maximum": 5,
            "description": "Quality of explanation (1=wrong, 3=adequate, 5=excellent)."
          },
          "attack_scenario_quality": {
            "type": ["integer", "null"],
            "minimum": 1,
            "maximum": 5,
            "description": "Quality of attack scenario (1-5), null if not provided."
          },
          "fix_quality": {
            "type": ["integer", "null"],
            "minimum": 1,
            "maximum": 5,
            "description": "Quality of fix suggestion (1-5), null if not provided."
          },
          "notes": {
            "type": ["string", "null"],
            "description": "Reviewer notes on this finding."
          }
        }
      }
    },

    "additional_findings_missed": {
      "type": "array",
      "description": "Vulnerabilities the model missed that human identified.",
      "items": {
        "type": "object",
        "properties": {
          "vulnerability_type": {
            "type": "string",
            "description": "Type of missed vulnerability."
          },
          "location": {
            "type": "string",
            "description": "Location of missed vulnerability."
          },
          "severity": {
            "type": "string",
            "enum": ["critical", "high", "medium", "low"],
            "description": "Severity of missed vulnerability."
          },
          "notes": {
            "type": "string",
            "description": "Description of what was missed."
          }
        }
      }
    },

    "overall_quality": {
      "type": "object",
      "description": "Overall assessment of model's analysis.",
      "required": ["score", "recommendation"],
      "properties": {
        "score": {
          "type": "number",
          "minimum": 1.0,
          "maximum": 5.0,
          "description": "Overall quality score (1-5)."
        },
        "strengths": {
          "type": "array",
          "items": { "type": "string" },
          "description": "What the model did well."
        },
        "weaknesses": {
          "type": "array",
          "items": { "type": "string" },
          "description": "Where the model fell short."
        },
        "recommendation": {
          "type": "string",
          "enum": ["pass", "marginal", "fail"],
          "description": "Overall pass/fail recommendation."
        }
      }
    },

    "review_metadata": {
      "type": "object",
      "description": "Metadata about the review process.",
      "properties": {
        "time_spent_minutes": {
          "type": "integer",
          "minimum": 0,
          "description": "Time spent on review in minutes."
        },
        "confidence": {
          "type": "string",
          "enum": ["low", "medium", "high"],
          "description": "Reviewer's confidence in their assessment."
        },
        "difficulty_rating": {
          "type": "string",
          "enum": ["easy", "medium", "hard"],
          "description": "How difficult this sample was to review."
        }
      }
    }
  },
  "additionalProperties": false
}
