{
  "snapshot_timestamp": "2025-12-18T19:05:08.912671",
  "sample_count": 46,
  "metrics": {
    "total_samples": 46,
    "vulnerable_samples": 46,
    "safe_samples": 0,
    "detection": {
      "accuracy": 0.9347826086956522,
      "precision": 1.0,
      "recall": 0.9347826086956522,
      "f1": 0.9662921348314606,
      "f2": 0.9471365638766519,
      "fpr": 0,
      "fnr": 0.06521739130434782,
      "tp": 43,
      "tn": 0,
      "fp": 0,
      "fn": 3
    },
    "target_finding": {
      "target_detection_rate": 0.6086956521739131,
      "lucky_guess_rate": 0.3488372093023256,
      "bonus_discovery_rate": 0.6739130434782609,
      "target_found_count": 28,
      "lucky_guess_count": 15
    },
    "finding_quality": {
      "finding_precision": 0.6050420168067226,
      "invalid_rate": 0.3949579831932773,
      "hallucination_rate": 0.008403361344537815,
      "over_flagging_score": 1.0217391304347827,
      "avg_findings_per_sample": 2.5869565217391304,
      "total_findings": 119,
      "valid_findings": 72,
      "invalid_findings": 47,
      "hallucinated_findings": 1
    },
    "reasoning_quality": {
      "mean_rcir": 0.9553571428571429,
      "mean_ava": 0.9642857142857143,
      "mean_fsv": 0.9285714285714286,
      "std_rcir": 0.09574826156038936,
      "std_ava": 0.11007882148158885,
      "std_fsv": 0.19884872724392932,
      "n_samples_with_reasoning": 28
    },
    "type_accuracy": {
      "exact_match_rate": 0.4642857142857143,
      "semantic_match_rate": 1.0,
      "partial_match_rate": 0.0,
      "n_samples": 28
    },
    "calibration": {
      "ece": 0.032051282051282215,
      "mce": 0.2333333333333334,
      "overconfidence_rate": 0.05128205128205132,
      "underconfidence_rate": 0.0,
      "brier_score": 0.04493589743589743,
      "n_samples": 39
    },
    "composite": {
      "true_understanding_score": 0.34965290464011695,
      "sui": 0.8138604188047119,
      "sui_components": {
        "f2": 0.9471365638766519,
        "target_detection": 0.6086956521739131,
        "finding_precision": 0.6050420168067226,
        "avg_reasoning": 0.9494047619047619,
        "calibration": 0.9679487179487178
      },
      "lucky_guess_indicator": 0.32608695652173914
    },
    "by_prompt_type": {
      "direct": {
        "total_samples": 38,
        "vulnerable_samples": 38,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.9736842105263158,
          "precision": 1.0,
          "recall": 0.9736842105263158,
          "f1": 0.9866666666666666,
          "f2": 0.9788359788359787,
          "fpr": 0,
          "fnr": 0.02631578947368421,
          "tp": 37,
          "tn": 0,
          "fp": 0,
          "fn": 1
        },
        "target_finding": {
          "target_detection_rate": 0.631578947368421,
          "lucky_guess_rate": 0.35135135135135137,
          "bonus_discovery_rate": 0.7368421052631579,
          "target_found_count": 24,
          "lucky_guess_count": 13
        },
        "finding_quality": {
          "finding_precision": 0.7682926829268293,
          "invalid_rate": 0.23170731707317074,
          "hallucination_rate": 0.012195121951219513,
          "over_flagging_score": 0.5,
          "avg_findings_per_sample": 2.1578947368421053,
          "total_findings": 82,
          "valid_findings": 63,
          "invalid_findings": 19,
          "hallucinated_findings": 1
        },
        "reasoning_quality": {
          "mean_rcir": 0.9791666666666666,
          "mean_ava": 1.0,
          "mean_fsv": 0.9583333333333334,
          "std_rcir": 0.06909634979907082,
          "std_ava": 0.0,
          "std_fsv": 0.09316949906249122,
          "n_samples_with_reasoning": 24
        },
        "type_accuracy": {
          "exact_match_rate": 0.5,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 24
        },
        "calibration": {
          "ece": 0.019736842105263313,
          "mce": 0.09999999999999998,
          "overconfidence_rate": 0.02631578947368418,
          "underconfidence_rate": 0.0,
          "brier_score": 0.02480263157894737,
          "n_samples": 38
        },
        "composite": {
          "true_understanding_score": 0.47512836970474964,
          "sui": 0.8606656164462647,
          "sui_components": {
            "f2": 0.9788359788359787,
            "target_detection": 0.631578947368421,
            "finding_precision": 0.7682926829268293,
            "avg_reasoning": 0.9791666666666666,
            "calibration": 0.9802631578947367
          },
          "lucky_guess_indicator": 0.3421052631578948
        }
      },
      "naturalistic": {
        "total_samples": 4,
        "vulnerable_samples": 4,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.75,
          "precision": 1.0,
          "recall": 0.75,
          "f1": 0.8571428571428571,
          "f2": 0.7894736842105263,
          "fpr": 0,
          "fnr": 0.25,
          "tp": 3,
          "tn": 0,
          "fp": 0,
          "fn": 1
        },
        "target_finding": {
          "target_detection_rate": 0.5,
          "lucky_guess_rate": 0.3333333333333333,
          "bonus_discovery_rate": 0.5,
          "target_found_count": 2,
          "lucky_guess_count": 1
        },
        "finding_quality": {
          "finding_precision": 0.2857142857142857,
          "invalid_rate": 0.7142857142857143,
          "hallucination_rate": 0.0,
          "over_flagging_score": 3.75,
          "avg_findings_per_sample": 5.25,
          "total_findings": 21,
          "valid_findings": 6,
          "invalid_findings": 15,
          "hallucinated_findings": 0
        },
        "reasoning_quality": {
          "mean_rcir": 0.75,
          "mean_ava": 0.75,
          "mean_fsv": 1.0,
          "std_rcir": 0.0,
          "std_ava": 0.0,
          "std_fsv": 0.0,
          "n_samples_with_reasoning": 2
        },
        "type_accuracy": {
          "exact_match_rate": 0.0,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 2
        },
        "calibration": {
          "ece": null,
          "mce": null,
          "overconfidence_rate": null,
          "underconfidence_rate": null,
          "brier_score": null,
          "n_samples": 0
        },
        "composite": {
          "true_understanding_score": 0.11904761904761904,
          "sui": 0.6235588972431078,
          "sui_components": {
            "f2": 0.7894736842105263,
            "target_detection": 0.5,
            "finding_precision": 0.2857142857142857,
            "avg_reasoning": 0.8333333333333334,
            "calibration": 0.5
          },
          "lucky_guess_indicator": 0.25
        }
      },
      "adversarial": {
        "total_samples": 4,
        "vulnerable_samples": 4,
        "safe_samples": 0,
        "detection": {
          "accuracy": 0.75,
          "precision": 1.0,
          "recall": 0.75,
          "f1": 0.8571428571428571,
          "f2": 0.7894736842105263,
          "fpr": 0,
          "fnr": 0.25,
          "tp": 3,
          "tn": 0,
          "fp": 0,
          "fn": 1
        },
        "target_finding": {
          "target_detection_rate": 0.5,
          "lucky_guess_rate": 0.3333333333333333,
          "bonus_discovery_rate": 0.25,
          "target_found_count": 2,
          "lucky_guess_count": 1
        },
        "finding_quality": {
          "finding_precision": 0.1875,
          "invalid_rate": 0.8125,
          "hallucination_rate": 0.0,
          "over_flagging_score": 3.25,
          "avg_findings_per_sample": 4.0,
          "total_findings": 16,
          "valid_findings": 3,
          "invalid_findings": 13,
          "hallucinated_findings": 0
        },
        "reasoning_quality": {
          "mean_rcir": 0.875,
          "mean_ava": 0.75,
          "mean_fsv": 0.5,
          "std_rcir": 0.125,
          "std_ava": 0.25,
          "std_fsv": 0.5,
          "n_samples_with_reasoning": 2
        },
        "type_accuracy": {
          "exact_match_rate": 0.5,
          "semantic_match_rate": 1.0,
          "partial_match_rate": 0.0,
          "n_samples": 2
        },
        "calibration": {
          "ece": 0.9,
          "mce": 0.9,
          "overconfidence_rate": 1.0,
          "underconfidence_rate": 0.0,
          "brier_score": 0.81,
          "n_samples": 1
        },
        "composite": {
          "true_understanding_score": 0.06640625,
          "sui": 0.537576754385965,
          "sui_components": {
            "f2": 0.7894736842105263,
            "target_detection": 0.5,
            "finding_precision": 0.1875,
            "avg_reasoning": 0.7083333333333334,
            "calibration": 0.09999999999999998
          },
          "lucky_guess_indicator": 0.25
        }
      }
    }
  }
}