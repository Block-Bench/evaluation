# OpenAI o3 via OpenRouter
name: "OpenAI o3"
provider: "openrouter"
model_id: "openai/o3"
region: "openrouter"  # Not used but required by schema

# Generation parameters
max_tokens: 16384  # o3 supports longer outputs
temperature: 1.0   # o3 requires temperature=1 for reasoning
timeout: 600       # o3 reasoning can take longer

# Retry configuration
max_retries: 3
retry_delay: 5.0   # Longer delay for expensive model

# Cost tracking (per 1M tokens) - OpenRouter pricing (o3 is expensive)
cost_per_input_token: 0.00001      # ~$10 per 1M input
cost_per_output_token: 0.00004     # ~$40 per 1M output

# Provider-specific settings
supports_json_mode: true
extra_params:
  app_name: "BlockBench"
  # o3 is a reasoning model - may need special handling
  reasoning_model: true
